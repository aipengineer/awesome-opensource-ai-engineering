# Functionary
![The AI Engineer presents Functionary](functionary_1920x192.png)
## Overview
Functionary executes functions and plugins within conversations. It determines when to trigger functions, understands outputs, and grounds responses in tool results.

## Description
Functionary is an LLM explicitly designed for interpreting and executing functions/plugins within conversations.

### 💡 Functionary Key Highlights

✅ Determines when to trigger functions based on conversation flow
✅ Understands function outputs and handles them appropriately
✅ Generates responses grounded in real function execution results

What sets Functionary apart:

🚀 Laser focused on function calling instead of general capabilities
⚡️ Fast and cost-effective compared to large general models like GPT-4
🎯 Accuracy approaching GPT-4 for function calling tasks
👍 Drop-in compatibility with OpenAI's platform

Use cases:
🗺️ Travel planning - Call trip planning functions
🏠 Real estate - Property valuation functions
📶 Telecom - Parse customer complaints

### 🤔 Why should The AI Engineer care about Functionary?

👉 Enables interactions with real-world data (⚡️fast and cost effective⚡️)

Functionary allows models to execute functions that can interact with real-time data, external APIs, etc. The open-source LLM provides up-to-date information vs just the model's fixed training data. And it does so faster and cheaper than huge general models.

🧮 Handles function execution details

Functionary determines when functions are needed, executes them, understands their outputs, and handles all the details automatically. Engineers don't have to coordinate function calling manually.

🔌 Drop-in replacement for OpenAI

Functionary is API-compatible with OpenAI. Engineers can swap it in and instantly upgrade the performance of apps that leverage function calling.

🎯 Specialized for Accuracy

Unlike large general models, Functionary is explicitly focused on accurate function execution. Its Accuracy for this particular task is rapidly approaching GPT-4.

👥 Supports parallel execution

Functionary can execute multiple functions in parallel within a conversation, allowing apps to leverage multiple real-time info sources.

## 📊 Tell me more about Functionary!
* 👷🏽‍♀️ Builders: Khai Mai, Musab Gultekin
* 👩🏽‍💼 Builders on LinkedIn: https://www.linkedin.com/in/khai-mai-a2a3b7ab/, https://www.linkedin.com/in/musab-gultekin/
* 👩🏽‍🏭 Builders on X: https://twitter.com/musabgultekin
* 👩🏽‍💻 Contributors: 13
* 💫 GitHub Stars: 610
* 🍴 Forks: 37
* 👁️ Watch: 12
* 🪪 License: MIT
* 🔗 Links: Below 👇🏽

## 🖇️ Where can I find out more about Functionary?
* GitHub Repository: https://github.com/MeetKai/functionary
* Official Website: https://meetkai.com/post/meetkai-functionary
* LinkedIn Page: https://www.linkedin.com/company/meetkai-inc/
* X Page: https://twitter.com/meetkaiinc
* Profile in The AI Engineer: https://github.com/theaiengineer/awesome-opensource-ai-engineering/blob/main/libraries/functionary/README.md

---
🧙🏽 Follow [The AI Engineer](https://www.linkedin.com/company/theaiengineer/) for more about Functionary and daily insights tailored to AI engineers. Subscribe to our [newsletter](http://theaiengineerco.substack.com). We are the AI community for hackers!

♻️ Repost this to help Functionary become more popular. Support AI Open-Source Libraries!

⚠️ If you want me to highlight your favorite AI library, open-source or not, please share it in the comments section!